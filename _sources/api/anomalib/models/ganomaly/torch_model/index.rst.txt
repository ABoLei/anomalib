:py:mod:`anomalib.models.ganomaly.torch_model`
==============================================

.. py:module:: anomalib.models.ganomaly.torch_model

.. autoapi-nested-parse::

   Torch models defining encoder, decoder, Generator and Discriminator.

   Code adapted from https://github.com/samet-akcay/ganomaly.



Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   anomalib.models.ganomaly.torch_model.Encoder
   anomalib.models.ganomaly.torch_model.Decoder
   anomalib.models.ganomaly.torch_model.Discriminator
   anomalib.models.ganomaly.torch_model.Generator




.. py:class:: Encoder(input_size: int, latent_vec_size: int, num_input_channels: int, n_features: int, extra_layers: int = 0, add_final_conv_layer: bool = True)

   Bases: :py:obj:`torch.nn.Module`

   Encoder Network.

   :param input_size: Size of input image
   :type input_size: int
   :param latent_vec_size: Size of latent vector z
   :type latent_vec_size: int
   :param num_input_channels: Number of input channels in the image
   :type num_input_channels: int
   :param n_features: Number of features per convolution layer
   :type n_features: int
   :param extra_layers: Number of extra layers since the network uses only a single encoder layer by default.
                        Defaults to 0.
   :type extra_layers: int

   .. py:method:: forward(self, input_tensor: torch.Tensor)

      Return latent vectors.



.. py:class:: Decoder(input_size: int, latent_vec_size: int, num_input_channels: int, n_features: int, extra_layers: int = 0)

   Bases: :py:obj:`torch.nn.Module`

   Decoder Network.

   :param input_size: Size of input image
   :type input_size: int
   :param latent_vec_size: Size of latent vector z
   :type latent_vec_size: int
   :param num_input_channels: Number of input channels in the image
   :type num_input_channels: int
   :param n_features: Number of features per convolution layer
   :type n_features: int
   :param extra_layers: Number of extra layers since the network uses only a single encoder layer by default.
                        Defaults to 0.
   :type extra_layers: int

   .. py:method:: forward(self, input_tensor)

      Return generated image.



.. py:class:: Discriminator(input_size: int, num_input_channels: int, n_features: int, extra_layers: int = 0)

   Bases: :py:obj:`torch.nn.Module`

   Discriminator.

       Made of only one encoder layer which takes x and x_hat to produce a score.

   :param input_size: Input image size.
   :type input_size: int
   :param num_input_channels: Number of image channels.
   :type num_input_channels: int
   :param n_features: Number of feature maps in each convolution layer.
   :type n_features: int
   :param extra_layers: Add extra intermediate layers. Defaults to 0.
   :type extra_layers: int, optional

   .. py:method:: forward(self, input_tensor)

      Return class of object and features.



.. py:class:: Generator(input_size: int, latent_vec_size: int, num_input_channels: int, n_features: int, extra_layers: int = 0, add_final_conv_layer: bool = True)

   Bases: :py:obj:`torch.nn.Module`

   Generator model.

   Made of an encoder-decoder-encoder architecture.

   :param input_size: Size of input data.
   :type input_size: int
   :param latent_vec_size: Dimension of latent vector produced between the first encoder-decoder.
   :type latent_vec_size: int
   :param num_input_channels: Number of channels in input image.
   :type num_input_channels: int
   :param n_features: Number of feature maps in each convolution layer.
   :type n_features: int
   :param extra_layers: Extra intermediate layers in the encoder/decoder. Defaults to 0.
   :type extra_layers: int, optional
   :param add_final_conv_layer: Add a final convolution layer in the decoder. Defaults to True.
   :type add_final_conv_layer: bool, optional

   .. py:method:: forward(self, input_tensor)

      Return generated image and the latent vectors.



