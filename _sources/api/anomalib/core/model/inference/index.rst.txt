:py:mod:`anomalib.core.model.inference`
=======================================

.. py:module:: anomalib.core.model.inference

.. autoapi-nested-parse::

   This module contains inference-related abstract class and its Torch and OpenVINO implementations.



Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   anomalib.core.model.inference.Inferencer
   anomalib.core.model.inference.TorchInferencer
   anomalib.core.model.inference.OpenVINOInferencer




.. py:class:: Inferencer

   Bases: :py:obj:`abc.ABC`

   Abstract class for the inference.

   This is used by both Torch and OpenVINO inference.

   .. py:method:: load_model(self, path: Union[str, pathlib.Path])
      :abstractmethod:

      Load Model.


   .. py:method:: pre_process(self, image: numpy.ndarray) -> Union[numpy.ndarray, torch.Tensor]
      :abstractmethod:

      Pre-process.


   .. py:method:: forward(self, image: Union[numpy.ndarray, torch.Tensor]) -> Union[numpy.ndarray, torch.Tensor]
      :abstractmethod:

      Forward-Pass input to model.


   .. py:method:: post_process(self, predictions: Union[numpy.ndarray, torch.Tensor], meta_data: Optional[Dict]) -> numpy.ndarray
      :abstractmethod:

      Post-Process.


   .. py:method:: predict(self, image: Union[str, numpy.ndarray], superimpose: bool = True) -> numpy.ndarray

      Perform a prediction for a given input image.

      The main workflow is (i) pre-processing, (ii) forward-pass, (iii) post-process.

      :param image: Input image whose output is to be predicted.
                    It could be either a path to image or numpy array itself.
      :type image: Union[str, np.ndarray]
      :param superimpose: If this is set to True, output predictions
                          will be superimposed onto the original image. If false, `predict`
                          method will return the raw heatmap.
      :type superimpose: bool

      :returns: Output predictions to be visualized.
      :rtype: np.ndarray


   .. py:method:: __call__(self, image: numpy.ndarray) -> numpy.ndarray

      Call predict on the Image.

      :param image: Input Image
      :type image: np.ndarray

      :returns: Output predictions to be visualized
      :rtype: np.ndarray



.. py:class:: TorchInferencer(config: Union[omegaconf.DictConfig, omegaconf.ListConfig], path: Union[str, pathlib.Path, anomalib.core.model.AnomalyModule])

   Bases: :py:obj:`Inferencer`

   PyTorch implementation for the inference.

   :param config: Configurable parameters that are used
                  during the training stage.
   :type config: DictConfig
   :param path: Path to the model ckpt file.
   :type path: Union[str, Path]

   .. py:method:: load_model(self, path: Union[str, pathlib.Path]) -> torch.nn.Module

      Load the PyTorch model.

      :param path: Path to model ckpt file.
      :type path: Union[str, Path]

      :returns: PyTorch Lightning model.
      :rtype: (nn.Module)


   .. py:method:: pre_process(self, image: numpy.ndarray) -> torch.Tensor

      Pre process the input image by applying transformations.

      :param image: Input image
      :type image: np.ndarray

      :returns: pre-processed image.
      :rtype: Tensor


   .. py:method:: forward(self, image: torch.Tensor) -> torch.Tensor

      Forward-Pass input tensor to the model.

      :param image: Input tensor.
      :type image: Tensor

      :returns: Output predictions.
      :rtype: Tensor


   .. py:method:: post_process(self, predictions: torch.Tensor, meta_data: Optional[Dict] = None) -> numpy.ndarray

      Post process the output predictions.

      :param predictions: Raw output predicted by the model.
      :type predictions: Tensor
      :param meta_data: Meta data. Post-processing step sometimes requires
                        additional meta data such as image shape. This variable comprises such info.
                        Defaults to {}.
      :type meta_data: Dict, optional

      :returns: Post processed predictions that are ready to be visualized.
      :rtype: np.ndarray



.. py:class:: OpenVINOInferencer(config: Union[omegaconf.DictConfig, omegaconf.ListConfig], path: Union[str, pathlib.Path, Tuple[bytes, bytes]])

   Bases: :py:obj:`Inferencer`

   OpenVINO implementation for the inference.

   :param config: Configurable parameters that are used
                  during the training stage.
   :type config: DictConfig
   :param path: Path to the openvino onnx, xml or bin file
   :type path: Union[str, Path]

   .. py:method:: load_model(self, path: Union[str, pathlib.Path, Tuple[bytes, bytes]])

      Load the OpenVINO model.

      :param path: Path to the onnx or xml and bin files
                   or tuple of .xml and .bin data as bytes.
      :type path: Union[str, Path, Tuple[bytes, bytes]]

      :returns:

                Input and Output blob names
                    together with the Executable network.
      :rtype: [Tuple[str, str, ExecutableNetwork]]


   .. py:method:: pre_process(self, image: numpy.ndarray) -> numpy.ndarray

      Pre process the input image by applying transformations.

      :param image: Input image.
      :type image: np.ndarray

      :returns: pre-processed image.
      :rtype: np.ndarray


   .. py:method:: forward(self, image: numpy.ndarray) -> numpy.ndarray

      Forward-Pass input tensor to the model.

      :param image: Input tensor.
      :type image: np.ndarray

      :returns: Output predictions.
      :rtype: np.ndarray


   .. py:method:: post_process(self, predictions: numpy.ndarray, meta_data: Optional[Dict] = None) -> numpy.ndarray

      Post process the output predictions.

      :param predictions: Raw output predicted by the model.
      :type predictions: np.ndarray
      :param meta_data: Meta data. Post-processing step sometimes requires
                        additional meta data such as image shape. This variable comprises such info.
                        Defaults to {}.
      :type meta_data: Dict, optional

      :returns: Post processed predictions that are ready to be visualized.
      :rtype: np.ndarray



